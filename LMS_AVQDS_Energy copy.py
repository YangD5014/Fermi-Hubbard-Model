from qiskit.circuit import QuantumCircuit
from qiskit.circuit.library import EvolvedOperatorAnsatz,StatePreparation
from qiskit.quantum_info.operators import SparsePauliOp
from qiskit_nature.second_q.hamiltonians import Hamiltonian
from qiskit.quantum_info import Statevector
from qiskit_algorithms.time_evolvers.variational.variational_principles import RealMcLachlanPrinciple
import datetime
import pickle
# è·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´ï¼Œç„¶åæ ¼å¼åŒ–ä¸ºæ—¥æœŸ+å°æ—¶+åˆ†é’Ÿ
formatted_now = datetime.datetime.now().strftime("%m-%d %H:%M")
from qiskit.primitives.estimator import Estimator
from FermiHubbard_model import Fermi_Hubbard
from MLVP_tool import Mclachlan_distance,M,V,AVQDS_optimize_value,Energy_Distance,McLachlan_distance_optimize,AVQDS_optimize_value_new,Energy_Distance_optimize
import scipy.linalg
import numpy as np
import copy
import logging


class LMS_AVQDS_Energy():
    def __init__(self,EndTime:float,N_site:int,U:float,J: float=1.0,TimeStep: float=0.01,Threshold: float=1e-3,max_add:int=2,max_theta: float=0.005,growing_mode:int=1,dt_max:float=0.1) -> None:
        self.N_site = N_site
        self.U = U
        self.J = J
        self.Hamiltonian_initial = Fermi_Hubbard(Ms=self.N_site,U=self.U,J=self.J).Hamiltonian
        self.H = self.Hamiltonian_initial
        self.n_qubit = self.Hamiltonian_initial.num_qubits
        eignvalue,vector = np.linalg.eigh(self.Hamiltonian_initial.to_matrix())
        self.start_en=eignvalue[0]
        
        self.growing_strategy_mode = growing_mode #0- McLachlan
        
        initial_state_circuit = QuantumCircuit(self.n_qubit)
        initial_state_circuit.append(StatePreparation(Statevector(data=vector[:,0])),range(self.n_qubit))
        self.initial_state = initial_state_circuit.to_instruction(label='Initial')
    
        del initial_state_circuit
    
        self.estimator = Estimator()
        
        self.timestep = TimeStep
        self.TimeNumStep = int(EndTime/TimeStep) #æ€»çš„æ—¶é—´æ­¥æ•°
        self.currentTime = 0.0
        self.max_theta = max_theta
        self.endtime = EndTime
        self.logger_init()
        self.HamiltonianPool_Init()
        #self.McLachlanPrinciple = RealMcLachlanPrinciple()
        self.currentOptimalValue = []
        
        #è¶…å‚æ•°
        self.cutoff_distance = Threshold
        self.cutoff_gradient = Threshold
        self.max_iter = max_add #æ¯ä¸€ä¸ªæ—¶é—´æ­¥é•¿æœ€å¤šåŠ å…¥çš„ç®—ç¬¦æ•°é‡
        
        #è®°å½•å†å²
        self.OptimialValueHistory = []
        self._IndexHistory = []
        self._num_pick = 0
        self.general_step =1
        
        self.max_theta = max_theta #æœ€å¤§å…è®¸çš„Î¸max è®ºæ–‡é‡Œæ˜¯ 0.005
        self.max_dt = dt_max #æœ€å¤§å…è®¸çš„æ—¶é—´æ­¥é•¿
        self.CircuitDepthHistory = []
        self.CircuitCNOTHistory = []
        self.AnsatzHistory = [] #å­˜ä¸€ä¸‹æ¯ä¸€è½®çš„Ansatz
        
        self.TimestepHistory = [] #æ¯æ¬¡çš„æ—¶é—´æ­¥é•¿
        self.max_theta_parameter = [] #æ¯æ¬¡çš„æœ€å¤§å‚æ•°
        
        self.differ_theta_unbounded=[]
        self.differ_theta_bounded=[]
        
        self.before_Matrix_History = []
        self.before_Vector_History =[]
        self.after_Matrix_History = []
        self.after_Vector_History = []
        
        self.MclachlanDistanceHistory = []
        self.MclachlanGradientHistory = []
        self.GroundStateEnergyHistory = [] #åŸºäºMLVPçš„èƒ½é‡
        self.GroundStateEnergyError = [] #åŸºæ€èƒ½é‡è¯¯å·®
        self.OverlapHistory = [] #è®°å½•ä¸‹ç¬æ—¶ç²¾ç¡®æ€å’Œç¬æ—¶å˜åˆ†æ€çš„é‡åˆåº¦
        self.EnergyGradientHistory = [] #è®°å½•ä¸‹ç¬æ—¶èƒ½é‡æ¢¯åº¦
        
        
        #è®°å½•ç¬æ—¶æ€ ç¬æ—¶èƒ½é‡ ç¬æ—¶åŸºæ€èƒ½é‡
        
        self.initial_ground_state = vector[:,0]  #è®°å½•H(0)çš„åˆæ€
        self.exact_state=[] #ç²¾ç¡®ç¬æ—¶èƒ½é‡
        self.exact_energy=[] #ç²¾ç¡®ç¬æ—¶æ€
        self.var_state=[]  #å˜åˆ†ç¬æ—¶æ€
        self.var_energy=[] #å˜åˆ†ç¬æ—¶èƒ½é‡
        self.exact_ground_state_energy=[] #ç²¾ç¡®åŸºæ€èƒ½é‡
        
        
        
        #æ ‡å¿—ä½
        self.FlagToStopAVQDS = False
        self.FlagToStopAll = False
        
        
    def Hamitonian_with_time(self,t:float):
        return LMSHamiltonian(N_site=self.N_site,gamma=gamma(t=t,T=self.T),h_z=self.hz)
    
    def logger_init(self,logger_name:str=__name__):
        
        # å®šä¹‰è®°å½•å™¨å¯¹è±¡
        self.logger = logging.getLogger(logger_name)
        # è®¾ç½®è®°å½•å™¨çº§åˆ«
        self.logger.setLevel(logging.DEBUG)
        # è®¾ç½®è¿‡æ»¤å™¨ åªæœ‰è¢«é€‰ä¸­çš„å¯ä»¥è®°å½•
        myfilter = logging.Filter(logger_name)
        # å®šä¹‰å¤„ç†å™¨-æ–‡ä»¶å¤„ç†å™¨
        filehandler = logging.FileHandler(filename=str(logger_name+formatted_now+'.log'), mode='w')
        filehandler.addFilter(myfilter)
        # formatter = logging.Formatter('%(asctime)s-%(levelname)s-\n%(message)s')
        # filehandler.setFormatter(formatter)
        # å®šä¹‰å¤„ç†å™¨-æ§åˆ¶å°å¤„ç†å™¨
        concolehander = logging.StreamHandler()
        concolehander.setLevel(logging.INFO)
        # è®°å½•å™¨ç»‘å®šhanderler
        self.logger.handlers.clear()
        self.logger.addHandler(filehandler)
        self.logger.addHandler(concolehander)
        self.logger.info('logger init done!')
    
    
    def HamiltonianPool_Init(self):
        self.HamiltonianPoolOp = []
        for paulistring,coeff in self.H.to_list():
            self.HamiltonianPoolOp.append(SparsePauliOp(data=paulistring))
        self.logger.info(f'LMS HamiltonianPool Init done!N-site={self.n_qubit}')
    
    def FirstStep(self):
        self.logger.info(f'-----------------ç¬¬{self.general_step}ä¸ªæ—¶é—´æ­¥é•¿,å½“å‰æ—¶é—´æ˜¯{self.currentTime}-------------------')
        self.currentTime = 0.0
        self.currentAnsatz = QuantumCircuit(self.n_qubit)
        self.currentAnsatz.append(self.initial_state,range(self.n_qubit))
        self.currentIndex = 0
        self.currentTime += self.timestep
        self.logger.info(f'ç›®å‰æ—¶é—´æ˜¯{self.currentTime}')
        self.logger.info(f'èµ·å§‹H(0)çš„åŸºæ€èƒ½é‡ä¸º={self.start_en}')

        #self.firstresult = []

        self._current_dist = 1.0
        self._current_gradient= 1.0
        self._current_iter = 0
        self._current_end_flag = False
        
        #è®°å½• Exact ç¬æ—¶èƒ½é‡
        self._current_hamitonian = self.Hamitonian_with_time(t=self.currentTime)
        exp_Ht = scipy.linalg.expm(-1j*self.Hamiltonian_initial.to_matrix()*self.timestep)# U(t=0)
        
        exact_state = exp_Ht@self.initial_ground_state
        exact_state = exact_state/np.linalg.norm(exact_state)
        exact_energy = np.real(exact_state.conj().T @ self._current_hamitonian.to_matrix() @ exact_state)
        exact_energy /= (exact_state.conj().T@exact_state)
        exact_energy = np.real(exact_energy)
        
        self.logger.info(f'exact_energy={exact_energy}')
        
        self.exact_state.append(exact_state)  #ä¿å­˜ä¸€ä¸‹ ç¬æ—¶ç²¾ç¡®æ€ ï½œexp(-iHt)|psi 0>
        self.exact_energy.append(exact_energy) #ä¿å­˜ä¸€ä¸‹ ç¬æ—¶ç²¾ç¡®èƒ½ <psi(t)|H|psi(t)>
        
        #self._current_dist,M,V = Mclachlan_distance(qc=self.currentAnsatz,initial_point=None,Hamiltonian=self._current_hamitonian)
        
        while self._current_end_flag is False: 
            self._current_iter += 1
            self.logger.info(f'æœ¬æ—¶é—´æ­¥é•¿å†…çš„ç¬¬{self._current_iter}æ¬¡è¿­ä»£')
            self._dist = []
            #self._en_dist = []
            self._gradient=[]
        
            for i in self.HamiltonianPoolOp:
                self.tmpAnsatz = copy.deepcopy(self.currentAnsatz)
                self.tmpAnsatz.append(EvolvedOperatorAnsatz(i),range(self.n_qubit))
                initial_point = np.append(self.currentOptimalValue,[0.0]*self._current_iter)
                if self.growing_strategy_mode ==0:
                    dist,M,V = Mclachlan_distance(qc=self.tmpAnsatz,initial_point=initial_point,Hamiltonian=self._current_hamitonian)
                    self._dist.append(dist)
                    self.logger.info(f'Iter={self._current_iter}|operator={i.paulis}ï½œDistance={self._dist[-1]}')
                    
                    #æŒ‘é€‰å‡ºæœ€å°çš„ Mclachlan Distanceæ•°å€¼
                    pick_index = np.argmin(np.abs(np.array(self._dist)))    
                    self._current_dist = np.min(np.abs(np.array(self._dist)))
                    self.MclachlanDistanceHistory.append(self._current_dist)
                    
                #energy_dist = Energy_Distance(qc=self.tmpAnsatz,initial_point=initial_point,Hamiltonian=self._current_hamitonian)
                if self.growing_strategy_mode ==1:
                    dist,M,V = Energy_Distance(qc=self.tmpAnsatz,initial_point=initial_point,Hamiltonian=self._current_hamitonian,time_diff=self.timestep)
                    self._dist.append(dist)
                    self.logger.info(f'Iter={self._current_iter}|operator={i.paulis}ï½œèƒ½é‡è·ç¦»={self._dist[-1]}')
                    
                    #æŒ‘é€‰å‡ºç»å¯¹å€¼æœ€å°çš„ èƒ½é‡å¾®åˆ†æ•°å€¼
                    pick_index = np.argmin(np.abs(np.array(self._dist)))    
                    self._current_dist = np.min(np.abs(np.array(self._dist)))
                    self.EnergyGradientHistory.append(self._current_dist)
            
            
            #æ›´æ–°å½“å‰çš„Ansatz
            self._IndexHistory.append(pick_index)
            
            self.currentAnsatz.append(EvolvedOperatorAnsatz(self.HamiltonianPoolOp[pick_index],parameter_prefix=f'Evolve{self.general_step:02d}-{self._current_iter:02d}',name=f'Operator{pick_index}-{self.general_step:03d}-{self._current_iter:02d}'),range(self.n_qubit))
            
            if self.growing_strategy_mode ==0:
                self.logger.info(f'è¿­ä»£{self._current_iter}å®Œæˆâœ…{pick_index+1} -th has been picked!Mclachlan Distance ={self._current_dist}')
            if self.growing_strategy_mode ==1:
                self.logger.info(f'è¿­ä»£{self._current_iter}å®Œæˆâœ…{pick_index+1} -th has been picked!Energy Distance ={self._current_dist}')
            #åˆ¤æ–­æ˜¯å¦åœ¨æ­¤æ—¶é—´æ­¥é•¿å†…ç»“æŸ
            if self._current_dist < self.cutoff_distance:
                # self.logger.info('è¾¾åˆ°åœæ­¢æ¡ä»¶!')
                self._current_end_flag = True
                self.logger.info(f'è¿­ä»£{self._current_iter}ç»“æŸâœ…!Mclachlan Distance ={self._current_dist}/{self.cutoff_distance}|æ»¡è¶³åœæ­¢è¦æ±‚ğŸ˜‰')
                break
            else:
                self.logger.info(f'è¿­ä»£{self._current_iter}ç»§ç»­ğŸ”„!Mclachlan Distance ={self._current_dist}/{self.cutoff_distance}')
                self._num_pick += 1
        
        #å‚æ•°ä¼˜åŒ– âˆ‡Î¸= M^-1@V * âˆ‡t
        self.logger.info(f'å¼€å§‹å‚æ•°ä¼˜åŒ–,åˆå§‹å€¼={initial_point}')
        optimal_value,self.current_M,self.current_V,self.max_parameter = AVQDS_optimize_value(ansatz_unbound=self.currentAnsatz,initial_point=initial_point,Hamiltonian=self._current_hamitonian,time_diff=self.timestep)
        self.TimestepHistory.append(self.timestep)
        
        

        
        self.logger.info(f'æœ¬æ¬¡çš„æ—¶é—´æ­¥é•¿æ˜¯={self.timestep}|æœ€å¤§å˜åŒ–å€¼={self.max_parameter}')
    
        dt = min(self.max_dt,np.abs(self.max_theta/self.max_parameter))
        self.timestep = dt
        
        self.logger.info(f'æ—¶é—´æ­¥é•¿å·²ç»æ›´æ–°={self.timestep}|{np.abs(self.max_theta/self.max_parameter)}')
        self.TimestepHistory.append(self.timestep)
        
        self.AnsatzHistory.append(self.currentAnsatz)
        self.CircuitDepthHistory.append(self.currentAnsatz.depth())#ç»Ÿè®¡çº¿è·¯æ·±åº¦
        self.CircuitCNOTHistory.append(self.currentAnsatz.decompose(reps=10).count_ops()['cx'])#ç»Ÿè®¡çº¿è·¯CNOTé—¨ä¸ªæ•°
        self.max_theta_parameter.append(self.max_parameter)
        
        
        
        
        
        var_state = Statevector(data=self.currentAnsatz.assign_parameters(optimal_value)).data
        var_energy = var_state.conj().T @ self._current_hamitonian.to_matrix() @ var_state
        var_energy = np.real(var_energy/(var_state.conj().T@var_state))
        
        self.current_var_state = var_state/np.linalg.norm(var_state)
        self.current_var_energy = var_energy
        self.current_exact_state = exact_state/np.linalg.norm(exact_state)
        
        
        self.var_state.append(var_state) #ä¿å­˜ä¸€ä¸‹ var_state ç¬æ—¶å˜åˆ†æ€
        self.var_energy.append(var_energy) #ä¿å­˜ä¸€ä¸‹ var_energy ç¬æ—¶å˜åˆ†èƒ½é‡
        
        overlap = np.abs((exact_state.conj().T@var_state)**2)
        self.OverlapHistory.append(overlap)
        
        
        #e,v = np.linalg.eigh(self._current_hamitonian.to_matrix())
        
        if self.growing_strategy_mode ==0:
            self.logger.info(f'æœ¬æ¬¡æ—¶é—´æ­¥é•¿ç»“æŸï½œå…±é€‰å–{self._current_iter}ä¸ªç®—ç¬¦:{self._IndexHistory[-self._current_iter:]}ï½œæœ€ä¼˜å‚æ•°ä¸º{optimal_value}ï½œMclachlan Distance={self._current_dist}\n|ç¬æ—¶ç²¾ç¡®èƒ½é‡={exact_energy}|ç¬æ—¶å˜åˆ†èƒ½é‡={var_energy}|ç¬æ—¶èƒ½é‡è¯¯å·®={var_energy-exact_energy}|ç²¾ç¡®ä¸å˜åˆ†æ€é‡åˆåº¦={overlap}')
        
        if self.growing_strategy_mode ==1:
            self.logger.info(f'æœ¬æ¬¡æ—¶é—´æ­¥é•¿ç»“æŸï½œå…±é€‰å–{self._current_iter}ä¸ªç®—ç¬¦:{self._IndexHistory[-self._current_iter:]}ï½œæœ€ä¼˜å‚æ•°ä¸º{optimal_value}ï½œèƒ½é‡è·ç¦»={self._current_dist}\n|ç¬æ—¶ç²¾ç¡®èƒ½é‡={exact_energy}|ç¬æ—¶å˜åˆ†èƒ½é‡={var_energy}|ç¬æ—¶èƒ½é‡è¯¯å·®={var_energy-exact_energy}|ç²¾ç¡®ä¸å˜åˆ†æ€é‡åˆåº¦={overlap}')
            
        #print(f'optimal_value={optimal_value},type={type(optimal_value)}')
         
        self.currentTime += self.timestep
        self.currentOptimalValue=optimal_value
        self.OptimialValueHistory.append(optimal_value) 
        #self.GroundStateEnergyError.append(result.values[0]-e[0])
        
        # self.before_Matrix_History.append(self.current_M)
        # self.before_Vector_History.append(self.current_V)
        
        self.general_step += 1
        
        # print(f'M Matrix={self.current_M}\n V vector={self.current_V}')
        
    
    
        
    def NextStep(self):
        self.logger.info(f'-----------------ç¬¬{self.general_step}ä¸ªæ—¶é—´æ­¥é•¿ï½œç›®å‰æ—¶é—´æ˜¯{self.currentTime}/{self.endtime}-------------------')
        self.logger.info(f'ç›®å‰æ—¶é—´æ˜¯{self.currentTime}')

        self._current_dist = 1.0
        self._current_gradient= 1.0        
        self._current_iter = 0
        self._current_hamitonian = self.Hamitonian_with_time(t=self.currentTime)
        self._current_end_flag = False
        self._before_ansatz = copy.deepcopy(self.currentAnsatz)
        self._current_add = []
        
        
        #è®°å½• Exact ç¬æ—¶èƒ½é‡
        self._current_hamitonian = self.Hamitonian_with_time(t=self.currentTime-self.timestep)
        
        exp_Ht = scipy.linalg.expm(-1j*self._current_hamitonian.to_matrix()*self.timestep)
        exact_state = exp_Ht@self.current_exact_state
        exact_state /= np.linalg.norm(exact_state)
        
        exact_energy = exact_state.conj().T @ self._current_hamitonian.to_matrix() @ exact_state
        exact_energy /= exact_state.conj().T@exact_state
        exact_energy = np.real(exact_energy)
        
        self.current_exact_state = exact_state
        self.exact_state.append(exact_state)  #ä¿å­˜ä¸€ä¸‹ ç¬æ—¶ç²¾ç¡®æ€ ï½œexp(-iHt)|psi 0>
        self.exact_energy.append(exact_energy) #ä¿å­˜ä¸€ä¸‹ ç¬æ—¶ç²¾ç¡®èƒ½ <psi(t)|H|psi(t)>
        
        if self.growing_strategy_mode ==0:
            self._current_dist,self.current_M,self.current_V= Mclachlan_distance(qc=self._before_ansatz,initial_point=self.currentOptimalValue,Hamiltonian=self._current_hamitonian)
            self.MclachlanDistanceHistory.append(self._current_dist)
            
            
        if self.growing_strategy_mode ==1:
            self._current_dist,self.current_M,self.current_V = Energy_Distance(qc=self._before_ansatz,initial_point=self.currentOptimalValue,Hamiltonian=self._current_hamitonian,time_diff=self.timestep)
            self.EnergyGradientHistory.append(self._current_dist)
            
               
        if self._current_dist < self.cutoff_distance: #å¦‚æœå½“å‰çš„é‡å­æ€ æ»¡è¶³åœæ­¢æ¡ä»¶
            self._current_end_flag = True
            
            if self.growing_strategy_mode ==0:
                self.logger.info(f'è¿­ä»£{self._current_iter}ç»“æŸâœ…!Mclachlan Distance ={self._current_dist}/{self.cutoff_distance}|æ»¡è¶³åœæ­¢è¦æ±‚ğŸ˜‰')
                
            if self.growing_strategy_mode ==1:
                self.logger.info(f'è¿­ä»£{self._current_iter}ç»“æŸâœ…!èƒ½é‡è·ç¦»={self._current_dist}/{self.cutoff_gradient}|æ»¡è¶³åœæ­¢è¦æ±‚ğŸ˜‰')

            # self.logger.info(f'è¿­ä»£{self._current_iter}ç»“æŸâœ…!Mclachlan Distance ={self._current_dist}/{self.cutoff_distance}|æ»¡è¶³åœæ­¢è¦æ±‚ğŸ˜‰|èƒ½é‡æ¢¯åº¦={en_dist}')
        else:    # self.logger.info(f'ä½¿ç”¨æ–°æŠ€æœ¯æµ‹é‡çš„Mclachlan Distance={self._current_dist2}')
            if self.growing_strategy_mode ==0:
                
                self.logger.info(f'ç›®å‰Mclachlan Distance={self._current_dist}/{self.cutoff_distance}|ä¸æ»¡è¶³åœæ­¢è¦æ±‚,å¼€å§‹å¯»æ‰¾ OperatorğŸ˜‰')
            if self.growing_strategy_mode ==1:
                self.logger.info(f'ç›®å‰èƒ½é‡è·ç¦» ={self._current_dist}/{self.cutoff_gradient}|ä¸æ»¡è¶³åœæ­¢è¦æ±‚,å¼€å§‹å¯»æ‰¾ OperatorğŸ˜‰')
            
            
        while self._current_end_flag is False:
            self._current_iter += 1
            if self._current_iter>self.max_iter-1:
                self._current_end_flag = True
                
            self._dist=[]
            self._en_dist = []
            self._gradient=[]
            self.logger.info(f'æœ¬æ—¶é—´æ­¥é•¿å†…çš„ç¬¬{self._current_iter}æ¬¡è¿­ä»£')


            for i in self.HamiltonianPoolOp:
                self.tmpAnsatz = copy.deepcopy(self._before_ansatz)
                #self.tmpAnsatz = self.tmpAnsatz.assign_parameters(self.currentOptimalValue)
                
                if self._current_iter > 1:
                    for j in self._current_add:
                        self.tmpAnsatz.append(j,range(self.n_qubit))
                        
                initial_point = np.append(self.currentOptimalValue,[0.0]*(self._current_iter))                
                self.tmpAnsatz.append(EvolvedOperatorAnsatz(i),range(self.n_qubit))
                
                if self.growing_strategy_mode ==0:
                    dist,_,_ = McLachlan_distance_optimize(qc=self.tmpAnsatz,initial_point=initial_point,Hamiltonian=self._current_hamitonian,before_M=self.current_M,before_V=self.current_V)
                    self._dist.append(dist)
                    self.logger.info(f'Iter={self._current_iter}|operator={i.paulis}|McLachlan Distance={dist}')
                    
                    pick_index = np.argmin(np.abs(np.array(self._dist)))    
                    self._current_dist = np.min(np.abs(np.array(self._dist)))
                    self.MclachlanDistanceHistory.append(self._current_dist)
                    
                if self.growing_strategy_mode ==1:
                    dist = Energy_Distance_optimize(qc=self.tmpAnsatz,initial_point=initial_point,Hamiltonian=self._current_hamitonian,before_M=self.current_M,before_V=self.current_V,time_diff=self.timestep)
                    self._dist.append(dist)
                    self.logger.info(f'Iter={self._current_iter}|operator={i.paulis}|èƒ½é‡è·ç¦»={dist}')
                    
                    pick_index = np.argmin(np.abs(np.array(self._dist)))    
                    self._current_dist = np.min(np.abs(np.array(self._dist)))
                    self.EnergyGradientHistory.append(self._current_dist)
                    
                        
            #æœ¬æ¬¡é€‰ä¸­çš„ operator å¯¹åº”çš„æ·»åŠ å—
            self._current_add.append(EvolvedOperatorAnsatz(self.HamiltonianPoolOp[pick_index],parameter_prefix=f'Evolve{self.general_step:02d}-{self._current_iter:02d}',name=f'Operator{pick_index}-{self.general_step:02d}-{self._current_iter:02d}'))
            self.currentAnsatz.append(self._current_add[-1],range(self.n_qubit))
            self._IndexHistory.append(pick_index)
            

            self.logger.info(f'è¿­ä»£{self._current_iter}å®Œæˆâœ…{pick_index+1} -th has been picked!Distance ={self._current_dist}')
            
            #åˆ¤æ–­æ˜¯å¦åœ¨æ­¤æ—¶é—´æ­¥é•¿å†…ç»“æŸ
            if self._current_dist < self.cutoff_distance:
                self._current_end_flag = True
                self.logger.info(f'è¿­ä»£{self._current_iter}ç»“æŸâœ…!Distance ={self._current_dist}/{self.cutoff_distance}|æ»¡è¶³åœæ­¢è¦æ±‚ğŸ˜‰')
                break
            else:
                self.logger.info(f'è¿­ä»£{self._current_iter}ç»§ç»­ğŸ”„!Distance ={self._current_dist}/{self.cutoff_distance}|ä¸æ»¡è¶³åœæ­¢è¦æ±‚ğŸ˜“')
                self._num_pick += 1
        
        #å‚æ•°ä¼˜åŒ– âˆ‡Î¸= M^-1@V * âˆ‡t
        initial_point = np.append(self.currentOptimalValue,[0.0]*self._current_iter)
        #initial_point = [0.0]*self._current_iter
        
        self.currentAnsatz = self._before_ansatz.copy()
        for j in self._current_add:
            self.currentAnsatz.append(j,range(self.n_qubit))
            
        
        #self.logger.info(f'å¼€å§‹å‚æ•°ä¼˜åŒ–,åˆå§‹å€¼={initial_point}')
        # optimal_value,self.current_M,self.current_V = AVQDS_optimize_value(ansatz_unbound=self.currentAnsatz,initial_point=initial_point,Hamiltonian=self._current_hamitonian,time_diff=self.timestep)
        
        optimal_value,max_parameters = AVQDS_optimize_value_new(ansatz_unbound=self.currentAnsatz,initial_point=initial_point,Hamiltonian=self._current_hamitonian,time_diff=self.timestep,before_V=self.current_V,before_M=self.current_M,theta_max=self.max_theta)
        self.logger.info(f'å‚æ•°ä¼˜åŒ–ç»“æœå¦‚ä¸‹:{optimal_value}|æœ€å¤§çš„å‚æ•°={max_parameters}')
        
        dt = min(self.max_dt,np.abs(self.max_theta/max_parameters))
        self.timestep = dt
        self.logger.info(f'æ—¶é—´æ­¥é•¿å·²ç»æ›´æ–°={self.timestep}|{np.abs(self.max_theta/max_parameters)}')  
        
        self.AnsatzHistory.append(self.currentAnsatz)
        self.CircuitDepthHistory.append(self.currentAnsatz.depth())#ç»Ÿè®¡çº¿è·¯æ·±åº¦
        self.CircuitCNOTHistory.append(self.currentAnsatz.decompose(reps=10).count_ops()['cx'])#ç»Ÿè®¡çº¿è·¯CNOTé—¨ä¸ªæ•°   
        self.currentTime += self.timestep
        self.currentOptimalValue=optimal_value
        self.OptimialValueHistory.append(optimal_value) 
        
        # self.after_Matrix_History.append(self.current_M)
        # self.after_Vector_History.append(self.current_V)
        self.general_step += 1
        
        
        var_state = Statevector(data=self.currentAnsatz.assign_parameters(optimal_value)).data
        var_energy = var_state.conj().T @ self._current_hamitonian.to_matrix() @ var_state
        var_energy = np.real(var_energy/(var_state.conj().T@var_state))
        
        self.var_state.append(var_state) #ä¿å­˜ä¸€ä¸‹ var_state ç¬æ—¶å˜åˆ†æ€
        self.var_energy.append(var_energy) #ä¿å­˜ä¸€ä¸‹ var_energy ç¬æ—¶å˜åˆ†èƒ½é‡
        overlap = np.abs((exact_state.conj().T@var_state)**2)
        self.OverlapHistory.append(overlap)
            
        self.logger.info(f'æœ¬æ¬¡æ—¶é—´æ­¥é•¿ç»“æŸï½œå…±é€‰å–{self._current_iter}ä¸ªç®—ç¬¦:{self._IndexHistory[-self._current_iter:]}ï½œæœ€ä¼˜å‚æ•°ä¸º{optimal_value}ï½œMclachlan Distance={self._current_dist}|ç¬æ—¶ç²¾ç¡®èƒ½é‡={exact_energy}|ç¬æ—¶å˜åˆ†èƒ½é‡={var_energy}|ç¬æ—¶èƒ½é‡è¯¯å·®={var_energy-exact_energy}|ç²¾ç¡®ä¸å˜åˆ†æ€é‡åˆåº¦={overlap}ï½œç›®å‰å‚æ•°è§„æ¨¡={self.currentAnsatz.num_parameters}')
        
        print(f'M Matrix={self.current_M}\nV vector={self.current_V}')
            
        
        
    def MLVP_run(self):
        self.FirstStep()
        while self.currentTime < self.endtime:
            if self.OverlapHistory[-1]<0.97:
                self.logger.info(f'æ¨¡æ‹Ÿå¤±è´¥ï¼é‡åˆåº¦è¿‡ä½={self.OverlapHistory[-1]}')
                break
            self.NextStep()
            self.save()
            
    def save(self):
        with open(f'./LMS-AVQDS-Energy{formatted_now}.pkl','wb') as f:
            pickle.dump(self,f)
        
        
        
    def exact_simulation(self):
        self.currentTime = 0.0
        self.TimeHistory=[]
        self.current_exact_state = self.initial_ground_state
        while self.currentTime < self.endtime:
            self.TimeHistory.append(self.currentTime)
            self._current_hamitonian = self.Hamitonian_with_time(t=self.currentTime)
            self.currentTime += self.timestep
            exp_Ht = scipy.linalg.expm(-1j*self._current_hamitonian.to_matrix()*self.timestep)
            exact_state = exp_Ht@self.current_exact_state
            exact_state /= np.linalg.norm(exact_state)
            exact_energy = exact_state.conj().T @ self._current_hamitonian.to_matrix() @ exact_state
            
            self.current_exact_state = exact_state
            exact_energy /= exact_state.conj().T@exact_state
            exact_energy = np.real(exact_energy)
            self.exact_state.append(exact_state)  #ä¿å­˜ä¸€ä¸‹ ç¬æ—¶ç²¾ç¡®æ€ ï½œexp
            self.exact_energy.append(exact_energy) #ä¿å­˜ä¸€ä¸‹ ç¬æ—¶ç²¾ç¡®èƒ½ <psi
        
    
    @staticmethod    
    def parameter_optimize(ansatz_unbound:QuantumCircuit,Hamiltonian:SparsePauliOp,initial_point:np.array,time_diff:float):
        M_matrix = M(qc=ansatz_unbound,initial_point=initial_point)
        V_vector = V(qc=ansatz_unbound,initial_point=initial_point,Hamiltonian=Hamiltonian)
        M_inverse = np.linalg.inv(M_matrix)
        optimal_value = M_inverse@V_vector*time_diff
        #print(f'optimal_value={optimal_value}')
        optimal_value = initial_point + optimal_value
        return optimal_value
        
        
        
        
    
                                